{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edccc430",
   "metadata": {},
   "source": [
    "Let's start by creating a simple linear model for digit recognition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b808a2bf",
   "metadata": {},
   "source": [
    "## Accessing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be929b9e",
   "metadata": {},
   "source": [
    "We'll download the famous [MNIST dataset](http://yann.lecun.com/exdb/mnist/) of handwritten digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5a1f709",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://s3.amazonaws.com/fast-ai-imageclas/mnist_png.tgz'\n",
    "tgz = 'mnist_png.tgz'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c944667",
   "metadata": {},
   "source": [
    "We can use `urlsave` from [fastcore](https://fastcore.fast.ai/) to download the dataset. However, we don't want to re-download it if we've downloaded it before. We can use Python's `Path` class to make it more convenient to work with the filesystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "72b141a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from fastcore.all import urlsave, untar_dir\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2bfe9ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfghome = Path.home()/'.fastai'\n",
    "archive = cfghome/'archive'\n",
    "if not (archive/tgz).exists():\n",
    "    archive.mkdir(exist_ok=True, parents=True)\n",
    "    urlsave(url, archive)\n",
    "\n",
    "data = cfghome/'data'\n",
    "dest = data/'mnist_png'\n",
    "if not dest.exists():\n",
    "    data.mkdir(exist_ok=True, parents=True)\n",
    "    untar_dir(archive/tgz, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85616431",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: use FastDownload when available"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a15fe0a",
   "metadata": {},
   "source": [
    "The dataset has separate folders for the training set and the test set (which we will use for validation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e613b0ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  training\r\n"
     ]
    }
   ],
   "source": [
    "!ls {dest}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca5b272",
   "metadata": {},
   "source": [
    "The training set is split into folders according to the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a5dd2ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  1  2  3  4  5  6  7\t8  9\r\n"
     ]
    }
   ],
   "source": [
    "trainpath = dest/'training'\n",
    "testpath = dest/'testing'\n",
    "!ls {trainpath}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a3937c",
   "metadata": {},
   "source": [
    "With `glob` we can get a list of all of the files in the training and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b49257b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jhoward/.fastai/data/mnist_png/training/8/7674.png'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "def getfiles(p): return list(glob(f'{p}/**/*.png', recursive=True))\n",
    "\n",
    "trainfiles = getfiles(trainpath)\n",
    "testfiles = getfiles(testpath)\n",
    "fname = trainfiles[0]\n",
    "fname"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a63b80",
   "metadata": {},
   "source": [
    "We can see from the path that this is the number \"8\", and is in the training set. We can open the image file using [torchvision](https://pytorch.org/vision/stable/index.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8b710f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.io import read_image\n",
    "img = read_image(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732e197f",
   "metadata": {},
   "source": [
    "This returns a `Tensor` (a multidimensional array). We can see its size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "19b1930a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8f6011",
   "metadata": {},
   "source": [
    "This shows that it is a single image of size 28x28."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010cf005",
   "metadata": {},
   "source": [
    "## Creating variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649164b3",
   "metadata": {},
   "source": [
    "For a linear model, we'll need independent variables (the pixel values) and a dependent variable (the labels). Let's first get the labels using a [list comprehension](https://docs.python.org/3/tutorial/datastructures.html#list-comprehensions):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e720b8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelfunc(p): return Path(p).parent.name\n",
    "y = [labelfunc(o) for o in trainfiles]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a236a4c",
   "metadata": {},
   "source": [
    "Let's check the distribution of labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a30b0a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'0': 5923,\n",
       "         '1': 6742,\n",
       "         '2': 5958,\n",
       "         '3': 6131,\n",
       "         '4': 5842,\n",
       "         '5': 5421,\n",
       "         '6': 5918,\n",
       "         '7': 6265,\n",
       "         '8': 5851,\n",
       "         '9': 5949})"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(sorted(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ecf6d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
